<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Smart Hat 2.0 - Intelligent Navigation for Visually Impaired</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-datalabels@2.0.0"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }
        
        :root {
            --primary: #ff7b00;
            --primary-dark: #e56d00;
            --secondary: #0056b3;
            --light: #fff;
            --dark: #333;
            --gray: #f5f5f5;
            --dark-gray: #444;
            --tech-blue: #1a73e8;
            --tech-green: #34a853;
            --tech-purple: #8e44ad;
        }
        
        body {
            background-color: #000;
            color: var(--light);
            overflow-x: hidden;
            position: relative;
        }
        
        canvas#starCanvas {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: -1;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            position: relative;
            z-index: 1;
        }
        
        header {
            text-align: center;
            padding: 60px 20px 40px;
            margin-bottom: 40px;
        }
        
        .logo {
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 15px;
            color: var(--light);
            text-shadow: 0 0 10px rgba(255, 255, 255, 0.5);
        }
        
        .logo span {
            color: var(--primary);
        }
        
        h1 {
            font-size: 3.5rem;
            margin-bottom: 20px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.5);
        }
        
        .quote {
            font-size: 1.8rem;
            font-style: italic;
            margin: 30px auto;
            max-width: 800px;
            color: var(--light);
            text-shadow: 1px 1px 2px rgba(0,0,0,0.3);
            background: rgba(255, 123, 0, 0.2);
            padding: 20px;
            border-radius: 10px;
            border-left: 4px solid var(--primary);
        }
        
        .collage-container {
            display: flex;
            justify-content: center;
            margin: 30px 0;
        }
        
        .collage {
            max-width: 80%;
            height: auto;
            border-radius: 10px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.5);
            border: 3px solid var(--primary);
        }
        
        .btn {
            display: inline-block;
            background: var(--secondary);
            color: var(--light);
            padding: 15px 40px;
            font-size: 1.2rem;
            text-decoration: none;
            border-radius: 50px;
            transition: all 0.3s ease;
            border: none;
            cursor: pointer;
            box-shadow: 0 4px 8px rgba(0,0,0,0.2);
            margin-top: 20px;
            font-weight: 600;
            letter-spacing: 1px;
        }
        
        .btn:hover {
            background: #003d82;
            transform: translateY(-3px);
            box-shadow: 0 6px 12px rgba(0,0,0,0.3);
        }
        
        .btn i {
            margin-left: 8px;
        }
        
        section {
            padding: 60px 20px;
            margin: 40px 0;
            background: rgba(0,0,0,0.5);
            border-radius: 15px;
            box-shadow: 0 5px 15px rgba(0,0,0,0.3);
            border: 1px solid rgba(255, 123, 0, 0.3);
        }
        
        h2 {
            font-size: 2.5rem;
            margin-bottom: 40px;
            text-align: center;
            position: relative;
            padding-bottom: 15px;
            color: var(--primary);
        }
        
        h2:after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 50%;
            transform: translateX(-50%);
            width: 100px;
            height: 4px;
            background: var(--primary);
            border-radius: 2px;
        }
        
        .section-description {
            text-align: center;
            max-width: 800px;
            margin: 0 auto 40px;
            font-size: 1.2rem;
            line-height: 1.7;
        }
        
        .columns {
            display: flex;
            flex-wrap: wrap;
            gap: 30px;
            margin-top: 30px;
        }
        
        .col {
            flex: 1;
            min-width: 300px;
            background: rgba(255, 123, 0, 0.1);
            padding: 25px;
            border-radius: 10px;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
            border: 1px solid rgba(255, 123, 0, 0.2);
            transition: transform 0.3s ease;
        }
        
        .col:hover {
            transform: translateY(-10px);
            border-color: var(--primary);
        }
        
        .col img {
            width: 100%;
            border-radius: 8px;
            margin-bottom: 20px;
            box-shadow: 0 5px 15px rgba(0,0,0,0.2);
            border: 1px solid rgba(255, 255, 255, 0.1);
        }
        
        h3 {
            font-size: 1.8rem;
            margin-bottom: 15px;
            color: var(--primary);
        }
        
        h4 {
            font-size: 1.4rem;
            margin: 20px 0 10px;
            color: var(--tech-blue);
        }
        
        p {
            margin-bottom: 15px;
            font-size: 1.1rem;
            line-height: 1.6;
        }
        
        ul {
            padding-left: 20px;
            margin-bottom: 20px;
        }
        
        li {
            margin-bottom: 10px;
            line-height: 1.6;
            position: relative;
            padding-left: 25px;
        }
        
        li:before {
            content: "•";
            color: var(--primary);
            position: absolute;
            left: 0;
            font-size: 1.4rem;
        }
        
        .architecture {
            display: flex;
            flex-wrap: wrap;
            gap: 30px;
            margin-top: 30px;
        }
        
        .arch-col {
            flex: 1;
            min-width: 300px;
            background: rgba(255, 123, 0, 0.1);
            padding: 25px;
            border-radius: 10px;
            border: 1px solid rgba(255, 123, 0, 0.2);
        }
        
        .integration {
            background: rgba(0, 86, 179, 0.1);
            padding: 30px;
            border-radius: 10px;
            margin-top: 40px;
            border: 1px solid rgba(0, 86, 179, 0.2);
        }
        
        .dashboard-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin-top: 30px;
        }
        
        .dashboard-item {
            background: rgba(255, 123, 0, 0.1);
            padding: 20px;
            border-radius: 10px;
            text-align: center;
            border: 1px solid rgba(255, 123, 0, 0.2);
        }
        
        .dashboard-item img {
            max-width: 100%;
            border-radius: 8px;
            margin-bottom: 15px;
            box-shadow: 0 5px 15px rgba(0,0,0,0.2);
        }
        
        .chart-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 30px;
            margin-top: 40px;
        }
        
        .chart-container {
            background: rgba(255, 255, 255, 0.05);
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 5px 15px rgba(0,0,0,0.2);
            height: 300px;
            position: relative;
        }
        
        .percentage-label {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            font-size: 1.8rem;
            font-weight: bold;
            color: var(--light);
            text-shadow: 0 0 8px rgba(255, 123, 0, 0.8);
        }
        
        .video-placeholder {
            width: 100%;
            height: 200px;
            background: rgba(255, 123, 0, 0.1);
            border: 2px dashed var(--primary);
            border-radius: 8px;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            margin-bottom: 20px;
            color: var(--primary);
        }
        
        .video-placeholder i {
            font-size: 4rem;
            margin-bottom: 15px;
        }
        
        .video-placeholder p {
            font-size: 1.2rem;
            text-align: center;
        }
        
        footer {
            text-align: center;
            padding: 40px 20px;
            margin-top: 60px;
            background: rgba(0,0,0,0.7);
            border-top: 1px solid rgba(255, 123, 0, 0.3);
        }
        
        .social-icons {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin: 20px 0;
        }
        
        .social-icons a {
            display: inline-flex;
            align-items: center;
            justify-content: center;
            width: 50px;
            height: 50px;
            border-radius: 50%;
            background: var(--primary);
            color: var(--light);
            font-size: 1.5rem;
            transition: all 0.3s ease;
            text-decoration: none;
        }
        
        .social-icons a:hover {
            transform: translateY(-5px);
            background: var(--secondary);
        }
        
        .copyright {
            margin-top: 20px;
            font-size: 1rem;
            color: var(--light);
            opacity: 0.8;
        }
        
        .university {
            margin-top: 10px;
            font-size: 1.1rem;
            color: var(--primary);
            font-weight: 500;
        }
        
        .tech-list {
            background: rgba(0, 0, 0, 0.3);
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
            border-left: 3px solid var(--tech-blue);
        }
        
        .tech-list h4 {
            margin-top: 0;
            color: var(--tech-green);
        }
        
        .flow-diagram {
            background: rgba(0, 0, 0, 0.2);
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
            border-left: 3px solid var(--tech-purple);
            font-family: monospace;
            line-height: 1.8;
        }
        
        .flow-arrow {
            color: var(--primary);
            margin: 0 10px;
        }
        
        @media (max-width: 768px) {
            h1 {
                font-size: 2.5rem;
            }
            
            .quote {
                font-size: 1.4rem;
                padding: 15px;
            }
            
            h2 {
                font-size: 2rem;
            }
            
            .columns, .architecture {
                flex-direction: column;
            }
            
            .collage {
                max-width: 100%;
            }
        }
    </style>
</head>
<body>
    <canvas id="starCanvas"></canvas>
    
    <div class="container">
        <header>
            <div class="logo">Smart<span>Aid</span> Hat</div>
            <h1>Intelligent Navigation for the Visually Impaired</h1>
            <p class="quote">"Improve your life consistently with strong support and enhanced mobility"</p>
            
            <div class="collage-container">
                <img src="https://i.postimg.cc/ZnpXftzV/photo-collage-5.png" alt="Smart Hat Collage" class="collage">
            </div>
            
            <a href="#how-it-works" class="btn">Discover How It Works <i class="fas fa-arrow-down"></i></a>
        </header>

        <section id="how-it-works">
            <h2>How Smart Hat Works</h2>
            <p class="section-description">The Smart Hat is an advanced wearable assistive system designed to improve mobility and independence for visually impaired users. It integrates voice-guided navigation, real-time object detection, and ultrasonic obstacle sensing for safe and independent movement.</p>
            
            <div class="columns">
                <div class="col">
                    <h3>Real-time Object Detection</h3>
                    <p>Powered by MobileNetV2 SSD model optimized for edge inference using TensorFlow Lite. The system processes dual-stream setup: low-resolution for rapid inference and high-resolution for logging.</p>
                    <p>Detections are filtered contextually with <span class="highlight">83% accuracy</span> across environments and <span class="highlight">95% directional accuracy</span>.</p>
                </div>
                <div class="col">
                    <h3>360° Obstacle Awareness</h3>
                    <p>Six ultrasonic sensors with temperature compensation provide comprehensive obstacle detection with <span class="highlight">92.2% accuracy</span>. Context-aware filtering prioritizes relevant alerts based on environment.</p>
                    <p>Kalman-filtered data ensures accurate distance measurements in all conditions.</p>
                </div>
                <div class="col">
                    <h3>Voice-Guided Navigation</h3>
                    <p>Intuitive voice feedback delivered through Web Speech API. Customizable verbosity levels accommodate different user needs.</p>
                    <p>GPS navigation with turn-by-turn guidance provides accurate routing with <span class="highlight">1.5m accuracy</span> in open environments.</p>
                </div>
            </div>
        </section>

        <section id="hardware">
            <h2>Hardware Components</h2>
            <p class="section-description">Carefully selected for performance, portability, and real-world usability with visually impaired users in mind.</p>
            
            <div class="columns">
                <div class="col">
                    <img src="https://i.postimg.cc/3xKzZcSF/New-Diagram-updated-ones.png" alt="Hardware Architecture">
                    <h3>Smart Hat Architecture</h3>
                    <p>The Raspberry Pi 5-based Smart Hat functions as a wearable edge device, integrating sensors (ultrasonic for obstacle detection/distance, IMX219 camera, GPS for location tracking) and an IMX500 processor for on-device AI/ML inference using MobileNet V2. It performs real-time local processing for object detection, proximity alerts, and communication, while also capturing voice commands for control.</p>
                </div>
                <div class="col">
                    <h3>Processing Unit</h3>
                    <p>Raspberry Pi 5 with ARM Cortex-A76 processor provides the computational power for real-time processing. Selected for its increased memory bandwidth and improved thermal handling.</p>
                    
                    <h3>Vision System</h3>
                    <p>Dual-camera setup: Sony IMX500 for daylight detection and Raspberry Pi Camera Module v2 (IMX219) with IR support for low-light conditions. Provides consistent coverage in all lighting situations.</p>
                    
                    <h3>Sensors & Power</h3>
                    <p>Six HC-SR04 ultrasonic sensors provide 360° awareness. Powered by rechargeable 5V/3A battery (10,000 mAh) with active thermal management using fan and heatsink to maintain stability.</p>
                </div>
            </div>
            
            <!-- New Hardware Features Section -->
            <div class="columns">
                <div class="col">
                    <h3>Key Hardware Features</h3>
                    <div class="tech-list">
                        <h4>Processing Core</h4>
                        <p>Raspberry Pi 5 with 8GB RAM</p>
                    </div>
                    <div class="tech-list">
                        <h4>Sensor Array</h4>
                        <p>6x HC-SR04 Ultrasonic + Dual Camera System</p>
                    </div>
                    <div class="tech-list">
                        <h4>Battery System</h4>
                        <p>10,000mAh @ 5V/3A with Dynamic Allocation</p>
                    </div>
                    <div class="tech-list">
                        <h4>Connectivity</h4>
                        <p>Wi-Fi 6 + Bluetooth 5.2 + Ngrok Tunneling</p>
                    </div>
                    
                    <h4>Real-Time Data Flow</h4>
                    <div class="flow-diagram">
                        <div>a. Ultrasonic sensors <span class="flow-arrow">→</span> Kalman filter <span class="flow-arrow">→</span> Risk assessment</div>
                        <div>b. Camera streams <span class="flow-arrow">→</span> MobileNetV2 SSD <span class="flow-arrow">→</span> Object mapping</div>
                        <div>c. Battery metrics <span class="flow-arrow">→</span> Power management algorithm</div>
                        <div>d. Sensor fusion <span class="flow-arrow">→</span> WebSocket <span class="flow-arrow">→</span> Voice feedback</div>
                    
                        <p style="color: orange; font-weight: bold;">Theoretical Explanation</p>
                        <p>a. Filters noisy distance data to assess collision risk.</p>
                        <p>b. Detects and maps objects from camera feed.</p>
                        <p>c. Optimizes power use based on battery metrics.</p>
                        <p>d. Combines sensor data, streams it, and provides voice alerts.</p>
                    
                        </div>
                </div>
                
                <div class="col">
                    <h3>Hardware-Software Integration</h3>
                    <div class="tech-list">
                        <h4>Sensor Integration</h4>
                        <p>RPi 5's GPIO pins interface with ultrasonic sensors</p>
                    </div>
                    <div class="tech-list">
                        <h4>Camera Integration</h4>
                        <p>MIPI camera ports stream to TensorFlow Lite models</p>
                    </div>
                    <div class="tech-list">
                        <h4>Power Management</h4>
                        <p>Power management IC coordinates with software load balancer</p>
                    </div>
                    <div class="tech-list">
                        <h4>Thermal Management</h4>
                        <p>Thermal sensors feed data to performance throttling system</p>
                    </div>
                </div>
            </div>
        </section>

        <section id="software">
            <h2>Software Architecture</h2>
            <p class="section-description">Smart Hat leverages cutting-edge software technologies for real-time processing and cloud integration.</p>
            
            <div class="columns">
                <div class="col">
                    <h3>Edge AI Processing</h3>
                    <p>The system uses TensorFlow Lite-optimized MobileNetV2 SSD model running directly on Raspberry Pi 5. This enables low-latency processing (average 230ms) without internet dependency.</p>
                    
                    <h3>Context-Aware Filtering</h3>
                    <p>Three operational modes: Home (filters indoor objects), Public (highlights people/vehicles), and Custom (user-defined). The system evaluates detection size, position, and danger score for intelligent alerts.</p>

                    <h3>Object-Detection</h3>
                    <img src="https://i.postimg.cc/0j4Frtmr/objectdetection-1.jpg" alt="Object Detection" width="400">
                    <p>The image detection results identify four people with high confidence levels: one at 98.0%, another at 86.2%, a third at 84.0%, and the fourth at 73.0%.</p>
                    
                    <h3>Voice Feedback System</h3>
                    <p>Browser-based text-to-speech via Web Speech API and SocketIO delivers clear, low-latency voice output. Temporal filtering prevents alert fatigue by suppressing identical messages within 4 seconds.</p>
                </div>
                <div class="col">
                    <img src="https://i.postimg.cc/hGYwcPS2/firebase-4.png" alt="Firebase Integration">
                    <h3>Firebase Integration</h3>
                    <p>Smart Hat utilizes Firebase Firestore for cloud-based data management and remote monitoring:</p>
                    <ul>
                     <p>1. Stores structured detection logs with timestamps, labels, confidence scores</p>
                     <p>2. Retains annotated video clips for critical detections</p>
                     <p>3. Enables remote configuration updates and monitoring</p>
                     <p>4. Provides secure data synchronization with TLS/SSL encryption</p>
                     <p>5. Allows historical analysis and model evaluation</p>
                    </ul>
                    <p>Firebase integration enables caregivers to review events, assess performance, and derive metrics while maintaining offline operation capabilities.</p>
                </div>
            </div>
            
            <!-- New Software Features Section -->
            <div class="columns">
                <div class="col">
                    <h3>Software Architecture</h3>
                    <div class="tech-list">
                        <h4>AI Engine</h4>
                        <p>TensorFlow Lite + MobileNetV2 SSD</p>
                    </div>
                    <div class="tech-list">
                        <h4>Sensor Fusion</h4>
                        <p>Kalman-filtered Ultrasonic Array</p>
                    </div>
                    <div class="tech-list">
                        <h4>Cloud Integration</h4>
                        <p>Firebase Firestore + GCP Maps API</p>
                    </div>
                    <div class="tech-list">
                        <h4>Voice Interface</h4>
                        <p>Web Speech API + 95% Directional Accuracy</p>
                    </div>
                    
                    <h4>Software-Hardware Synergy</h4>
                    <ul>
                        <p>1. TensorFlow Lite optimizations for ARM Cortex-A76</p>
                        <p>2. Dual camera synchronization via Picamera2 API</p>
                        <p>3. Real-time sensor polling at 20Hz intervals</p>
                        <p>4. Power-aware thread scheduling</p>
                    </ul>
                </div>
                
                <div class="col">
                    <h3>Processing Pipeline</h3>
                    <div class="flow-diagram">
                        <div>Frame capture <span class="flow-arrow">→</span> Low-res inference <span class="flow-arrow">→</span> High-res logging</div>
                        <div>Ultrasonic data <span class="flow-arrow">→</span> Noise filtering <span class="flow-arrow">→</span> Proximity mapping</div>
                        <div>Fusion engine <span class="flow-arrow">→</span> Priority scoring <span class="flow-arrow">→</span> Voice alerts</div>
                        <div>System health <span class="flow-arrow">→</span> Firebase <span class="flow-arrow">→</span> Remote monitoring</div>
                          
                        <p><strong style="color: blue;">1. Camera System:</strong> The system captures video frames. First, it uses low-resolution images to quickly detect key information. If something important is found, it saves a high-resolution image for detailed logging.</p>
                        <p><strong style="color: blue;">2. Ultrasonic Sensor:</strong> This sensor sends sound waves to detect nearby objects. It removes background noise and creates a map of how close objects are.</p>
                        <p><strong style="color: blue;">3. Fusion Engine:</strong> The system combines camera and sensor data. It gives priority scores to what it detects and plays voice alerts if action is needed.</p>
                        <p><strong style="color: blue;">4. Remote Monitoring:</strong> The system checks its own health and sends data to Firebase (a cloud platform). This allows for remote tracking and monitoring from anywhere.</p>
                    </div>  
                    <h4>Performance Metrics</h4>
                    <ul>
                        <p>1. Object detection latency: 230ms</p>
                        <p>2. Ultrasonic processing: 20Hz sampling</p>
                        <p>3. Voice feedback latency: &lt;100ms</p>
                        <p>4. Data sync to Firebase: 500ms intervals</p>
                    </ul>
                </div>
            </div>
        </section>

        <section id="dashboard">
            <h2>Interactive Dashboard</h2>
            <p class="section-description">Real-time monitoring and analytics for users and caregivers.</p>
            
            <div class="dashboard-grid">
                <div class="dashboard-item">
                    <img src="https://i.postimg.cc/xCbZCD8n/dashboard-updated-newones-4.png" alt="Dashboard View">
                    <h3>Real-time Monitoring</h3>
                    <p>Built with Plotly Dash, the dashboard provides live tracking of sensor data, performance metrics, and detection logs.</p>
                </div>
                <div class="dashboard-item">
                    <img src="https://i.postimg.cc/zXXY7fcX/Dashboard.png" alt="Dashboard View">
                    <h3>Analytics & Trends</h3>
                    <p>Time-series graphs track battery drain, detection frequency, and system performance. Historical data helps identify trends.</p>
                </div>
            </div>
        </section>

        <section id="integration">
            <h2>Hardware & Software Integration</h2>
            <p class="section-description">Seamless architecture for reliable real-time performance.</p>
            
            <div class="integration">
                <h3 style="text-align: center; color: var(--light); margin-bottom: 30px;">Three-Layer Integration Architecture</h3>
                
                <div class="architecture">
                    <div class="arch-col">
                        <h4>Device Layer</h4>
                        <ul>
                            <p>Dual-camera vision system</p>
                            <p>Six ultrasonic sensors</p>
                            <p>5V/3A rechargeable battery</p>
                            <p>Thermal management system</p>
                        </ul>
                    </div>
                    <div class="arch-col">
                        <h4>Edge Processing Layer</h4>
                        <ul>
                            <p>Raspberry Pi 5 computation</p>
                            <p>TensorFlow Lite inference</p>
                            <p>Real-time sensor fusion</p>
                            <p>Local decision-making</p>
                        </ul>
                    </div>
                    <div class="arch-col">
                        <h4>Cloud Support Layer</h4>
                        <ul>
                            <p>Firebase Firestore logging</p>
                            <p>Remote monitoring via Ngrok</p>
                            <p>Web interface for control</p>
                            <p>Analytics and review system</p>
                        </ul>
                    </div>
                </div>
                
                <p style="text-align: center; margin-top: 30px; font-size: 1.1rem;">This architecture maintains sub-500ms response times through edge inference, asynchronous communication, and performance optimizations. The system achieves 230ms for object detection, 80ms for ultrasonic evaluation, and 100ms for voice dispatch.</p>
            </div>
        </section>
        
        <section id="visualizations">
            <h2>Performance Metrics</h2>
            <p class="section-description">Key performance indicators from extensive testing of the Smart Hat system.</p>
            
            <div class="chart-grid">
                <div class="chart-container">
                    <canvas id="accuracyChart"></canvas>
                    <div class="percentage-label">83%</div>
                </div>
                <div class="chart-container">
                    <canvas id="latencyChart"></canvas>
                    <div class="percentage-label">230ms</div>
                </div>
                <div class="chart-container">
                    <canvas id="batteryChart"></canvas>
                    <div class="percentage-label">6h 40m</div>
                </div>
            </div>
        </section>
        
        <footer>
            <div class="social-icons">
                <a href="#"><i class="fab fa-linkedin-in"></i></a>
                <a href="#"><i class="fab fa-instagram"></i></a>
                <a href="#"><i class="fab fa-github"></i></a>
            </div>
            
            <div class="university">University of the Pacific Project</div>
            <div class="copyright">© 2025 SmartVision Pro. All Rights Reserved.</div>
        </footer>
    </div>

    <script>
        // Star particle effect
        const canvas = document.getElementById('starCanvas');
        const ctx = canvas.getContext('2d');
        let stars = [];
        const numStars = 300;

        // Resize canvas
        function resizeCanvas() {
            canvas.width = window.innerWidth;
            canvas.height = window.innerHeight;
            initStars();
        }
        
        window.addEventListener('resize', resizeCanvas);
        
        // Star class
        class Star {
            constructor() {
                this.reset();
            }
            reset() {
                this.x = Math.random() * canvas.width;
                this.y = Math.random() * canvas.height;
                this.size = Math.random() * 1.5;
                this.speed = Math.random() * 0.5 + 0.2;
                this.alpha = Math.random() * 0.5 + 0.5;
            }
            update() {
                this.y += this.speed;
                if (this.y > canvas.height) {
                    this.reset();
                    this.y = 0;
                }
            }
            draw() {
                ctx.beginPath();
                ctx.arc(this.x, this.y, this.size, 0, Math.PI * 2);
                ctx.fillStyle = `rgba(255, 255, 255, ${this.alpha})`;
                ctx.fill();
            }
        }

        // Initialize stars
        function initStars() {
            stars = [];
            for (let i = 0; i < numStars; i++) {
                stars.push(new Star());
            }
        }

        // Animation loop
        function animate() {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            for (let star of stars) {
                star.update();
                star.draw();
            }
            requestAnimationFrame(animate);
        }

        // Initialize and start animation
        resizeCanvas();
        animate();

       document.addEventListener('DOMContentLoaded', function () {
    // Ensure ChartDataLabels plugin is registered globally
    if (Chart && Chart.plugins) Chart.plugins.register(ChartDataLabels);

    // Accuracy chart (bar)
    const accuracyCtx = document.getElementById('accuracyChart').getContext('2d');
    new Chart(accuracyCtx, {
        type: 'bar',
        data: {
            labels: ['Object Detection', 'Directional Accuracy', 'Obstacle Detection'],
            datasets: [{
                label: 'Accuracy (%)',
                data: [83, 95, 92.2],
                backgroundColor: [
                    'rgba(255, 123, 0, 0.7)',
                    'rgba(0, 86, 179, 0.7)',
                    'rgba(50, 168, 82, 0.7)'
                ],
                borderColor: [
                    'rgba(255, 123, 0, 1)',
                    'rgba(0, 86, 179, 1)',
                    'rgba(50, 168, 82, 1)'
                ],
                borderWidth: 1
            }]
        },
        options: {
            responsive: true,
            maintainAspectRatio: false,
            plugins: {
                legend: { display: false },
                title: {
                    display: true,
                    text: 'Detection Accuracy Metrics',
                    color: '#fff',
                    font: { size: 16 }
                },
                datalabels: {
                    anchor: 'end',
                    align: 'top',
                    color: '#fff',
                    font: { weight: 'bold' },
                    formatter: (value) => value + '%'
                }
            },
            scales: {
                y: {
                    beginAtZero: true,
                    max: 100,
                    ticks: { color: '#fff' },
                    grid: { color: 'rgba(255, 255, 255, 0.1)' }
                },
                x: {
                    ticks: { color: '#fff' },
                    grid: { display: false }
                }
            }
        },
        plugins: [ChartDataLabels]
    });

    // Latency chart (line)
    const latencyCtx = document.getElementById('latencyChart').getContext('2d');
    new Chart(latencyCtx, {
        type: 'line',
        data: {
            labels: ['Object Detection', 'Ultrasonic', 'Voice Feedback', 'Total System'],
            datasets: [{
                label: 'Latency (ms)',
                data: [230, 80, 100, 410],
                fill: false,
                borderColor: 'rgba(255, 123, 0, 1)',
                tension: 0.1,
                pointBackgroundColor: '#fff',
                pointBorderColor: 'rgba(255, 123, 0, 1)',
                pointRadius: 5,
                pointHoverRadius: 7
            }]
        },
        options: {
            responsive: true,
            maintainAspectRatio: false,
            plugins: {
                legend: { display: false },
                title: {
                    display: true,
                    text: 'System Latency Performance',
                    color: '#fff',
                    font: { size: 16 }
                },
                datalabels: {
                    color: '#fff',
                    font: { weight: 'bold' },
                    formatter: (value) => value + 'ms',
                    align: 'top',
                    offset: 5
                }
            },
            scales: {
                y: {
                    beginAtZero: true,
                    ticks: { color: '#fff' },
                    grid: { color: 'rgba(255, 255, 255, 0.1)' }
                },
                x: {
                    ticks: { color: '#fff' },
                    grid: { color: 'rgba(255, 255, 255, 0.1)' }
                }
            }
        },
        plugins: [ChartDataLabels]
    });

    // Battery chart (doughnut)
    const batteryCtx = document.getElementById('batteryChart').getContext('2d');
    new Chart(batteryCtx, {
        type: 'doughnut',
        data: {
            labels: ['Camera Usage', 'AI Processing', 'Sensors', 'Web Interface'],
            datasets: [{
                label: 'Power Consumption (%)',
                data: [35, 30, 20, 15],
                backgroundColor: [
                    'rgba(255, 123, 0, 0.7)',
                    'rgba(0, 86, 179, 0.7)',
                    'rgba(50, 168, 82, 0.7)',
                    'rgba(220, 53, 69, 0.7)'
                ],
                borderColor: [
                    'rgba(255, 123, 0, 1)',
                    'rgba(0, 86, 179, 1)',
                    'rgba(50, 168, 82, 1)',
                    'rgba(220, 53, 69, 1)'
                ],
                borderWidth: 1
            }]
        },
        options: {
            responsive: true,
            maintainAspectRatio: false,
            plugins: {
                legend: {
                    position: 'right',
                    labels: {
                        color: '#fff',
                        font: { size: 12 }
                    }
                },
                title: {
                    display: true,
                    text: 'Power Consumption Distribution',
                    color: '#fff',
                    font: { size: 16 }
                },
                datalabels: {
                    color: '#fff',
                    font: { weight: 'bold' },
                    formatter: (value) => value + '%'
                }
            },
            cutout: '62%'
        },
        plugins: [ChartDataLabels]
    });
});
    </script>
</body>
</html>